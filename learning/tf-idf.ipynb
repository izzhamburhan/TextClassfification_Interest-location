{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Assuming you have already imported necessary libraries and cleaned your text data as mentioned before\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#svm <- TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "# bert <- TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attempt hari tu act like smart deep tech entre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mosti cradle ni clueless whats going malaysias...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hightech exports country china 942b hong kong ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hightech exports country china 942b hong kong ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tbh malaysia many tech talents dont actually n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>smartwatch one better sport ea garmin amazfit ...</td>\n",
       "      <td>Terengganu</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28836</th>\n",
       "      <td>abearfromsea heaven football maracana</td>\n",
       "      <td>Terengganu</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28837</th>\n",
       "      <td>king pele former youth sport minister khairykj...</td>\n",
       "      <td>Terengganu</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28838</th>\n",
       "      <td>love football</td>\n",
       "      <td>Terengganu</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28839</th>\n",
       "      <td>kb football clinic although internet connectio...</td>\n",
       "      <td>Terengganu</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28840 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    location  \\\n",
       "0      attempt hari tu act like smart deep tech entre...         NaN   \n",
       "1      mosti cradle ni clueless whats going malaysias...         NaN   \n",
       "2      hightech exports country china 942b hong kong ...         NaN   \n",
       "3      hightech exports country china 942b hong kong ...         NaN   \n",
       "4      tbh malaysia many tech talents dont actually n...         NaN   \n",
       "...                                                  ...         ...   \n",
       "28835  smartwatch one better sport ea garmin amazfit ...  Terengganu   \n",
       "28836              abearfromsea heaven football maracana  Terengganu   \n",
       "28837  king pele former youth sport minister khairykj...  Terengganu   \n",
       "28838                                      love football  Terengganu   \n",
       "28839  kb football clinic although internet connectio...  Terengganu   \n",
       "\n",
       "         interest  \n",
       "0      Technology  \n",
       "1      Technology  \n",
       "2      Technology  \n",
       "3      Technology  \n",
       "4      Technology  \n",
       "...           ...  \n",
       "28835      Sports  \n",
       "28836      Sports  \n",
       "28837      Sports  \n",
       "28838      Sports  \n",
       "28839      Sports  \n",
       "\n",
       "[28840 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interest-location.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            1\n",
       "location    12700\n",
       "interest        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 1\n"
     ]
    }
   ],
   "source": [
    "missing_values = df['text'].isna().sum()\n",
    "print(\"Number of missing values:\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            0\n",
       "location    12699\n",
       "interest        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['text'], inplace=True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].fillna(\"No text available\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame 'df' with 'text' and 'label' columns\n",
    "X = df['text']  # Features\n",
    "y = df['interest']  # Labels\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you have:\n",
    "# X_train: Training text data\n",
    "# y_train: Corresponding training labels\n",
    "# X_test: Testing text data\n",
    "# y_test: Corresponding testing labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=29000, stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')  # You can try different kernels (linear, rbf, etc.)\n",
    "svm_classifier.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23920           Sports\n",
       "25159           Sports\n",
       "12011    Entertainment\n",
       "25378           Sports\n",
       "18407        Education\n",
       "             ...      \n",
       "28480           Sports\n",
       "3739        Technology\n",
       "25273           Sports\n",
       "12517    Entertainment\n",
       "25960           Sports\n",
       "Name: interest, Length: 5768, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Sports', 'Entertainment', ..., 'Sports',\n",
       "       'Entertainment', 'Sports'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "# y_pred = svm_classifier.predict(tfidf_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Education       0.95      0.95      0.95      1003\n",
      "Entertainment       0.96      0.97      0.97      1151\n",
      "   FoodnDrink       0.97      0.96      0.97       817\n",
      "     Politics       0.97      0.97      0.97       755\n",
      "       Sports       0.98      0.98      0.98      1116\n",
      "   Technology       0.96      0.96      0.96       926\n",
      "\n",
      "     accuracy                           0.96      5768\n",
      "    macro avg       0.97      0.96      0.96      5768\n",
      " weighted avg       0.96      0.96      0.96      5768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = svm_classifier.predict(tfidf_test)\n",
    "\n",
    "# Evaluate the classifier using the test data\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Education       0.95      0.94      0.95      1003\n",
      "Entertainment       0.93      0.96      0.94      1151\n",
      "   FoodnDrink       0.95      0.95      0.95       817\n",
      "     Politics       0.96      0.96      0.96       755\n",
      "       Sports       0.97      0.96      0.96      1116\n",
      "   Technology       0.95      0.94      0.94       926\n",
      "\n",
      "     accuracy                           0.95      5768\n",
      "    macro avg       0.95      0.95      0.95      5768\n",
      " weighted avg       0.95      0.95      0.95      5768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split your dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the number of features as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')  # You can try different kernels (linear, rbf, etc.)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99066bc38f834c47aefc889c2815397e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Izzham Burhan\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the training and testing data\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'commonwealthgames2022 indian badminton player lakshya sen beats ng tze yong malaysia 1921 219 2116 win mens singles gold victory india records 20th gold cwg2022'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m values])\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m table \u001b[39m=\u001b[39m _nandict({val: i \u001b[39mfor\u001b[39;00m i, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([table[v] \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnan_value\n\u001b[1;32m--> 158\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'commonwealthgames2022 indian badminton player lakshya sen beats ng tze yong malaysia 1921 219 2116 win mens singles gold victory india records 20th gold cwg2022'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Izzham Burhan\\Documents\\Python Scripts\\TextClassification-Interestbasedonlocation\\learning\\tf-idf.ipynb Cell 21\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_labels_encoded \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_labels_encoded \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39;49mtransform(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:139\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[1;32mc:\\Users\\Izzham Burhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[39mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    225\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'commonwealthgames2022 indian badminton player lakshya sen beats ng tze yong malaysia 1921 219 2116 win mens singles gold victory india records 20th gold cwg2022'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_labels_encoded = label_encoder.fit_transform(X_train)\n",
    "test_labels_encoded = label_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'BatchEncoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Izzham Burhan\\Documents\\Python Scripts\\TextClassification-Interestbasedonlocation\\learning\\tf-idf.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTensorDataset(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_encodings[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m],  \u001b[39m# Input IDs\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_encodings[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m],  \u001b[39m# Attention mask\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mtensor(train_encodings)  \u001b[39m# Labels (assuming 'interest' contains numeric labels)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Izzham%20Burhan/Documents/Python%20Scripts/TextClassification-Interestbasedonlocation/learning/tf-idf.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'BatchEncoding'"
     ]
    }
   ],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    train_encodings['input_ids'],  # Input IDs\n",
    "    train_encodings['attention_mask'],  # Attention mask\n",
    "    torch.tensor(train_encodings)  # Labels (assuming 'interest' contains numeric labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 3463, 2712,  ...,    0,    0,    0],\n",
       "        [ 101, 2082, 2045,  ...,    0,    0,    0],\n",
       "        [ 101, 2292, 2404,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2824, 4888,  ...,    0,    0,    0],\n",
       "        [ 101, 3522, 4440,  ...,    0,    0,    0],\n",
       "        [ 101, 3463, 5297,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
